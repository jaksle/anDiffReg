{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599def31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky\n",
    "import anDiffReg as an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc294059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplary data: mixture of FBMs\n",
    "# this is the same system as considered in the \"Non-parametric deconvolution\" section of the article\n",
    "\n",
    "ln = 100\n",
    "n = 10**4\n",
    "dt =  1\n",
    "ts = dt*np.arange(1,ln+1)\n",
    "\n",
    "msd = np.empty((ln-1,n), dtype = np.float64)\n",
    "S = np.empty((ln,ln), dtype = np.float64)\n",
    "\n",
    "for k in range(n):\n",
    "    # (logD, alpha) distribution is 2 rectangles \n",
    "    if np.random.rand() < 1/2:\n",
    "        alpha = np.random.uniform(0.4,0.6)\n",
    "    else:\n",
    "        alpha = np.random.uniform(0.8,1.0)\n",
    "    logD = np.random.uniform(-1.0,1.0)\n",
    "\n",
    "    for i in range(ln):\n",
    "        for j in range(i,ln):\n",
    "            S[i,j] = 10**logD * (ts[i]**alpha + ts[j]**alpha - np.abs(ts[j] - ts[i])**alpha)\n",
    "            S[j,i] = S[i,j]\n",
    "    A = cholesky(S, lower=False)\n",
    "    xi = np.random.randn(len(ts))\n",
    "    X = A.T @ xi\n",
    "\n",
    "    msd[:,k] = np.ravel(an.tamsd(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f3d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting\n",
    "\n",
    "ols, covOLS = an.fit_ols(msd, 1, dt)\n",
    "gls, covGLS = an.fit_gls(msd, 1, dt, ols[1,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65294be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting kde\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# this is for the gls estimate \n",
    "kde = gaussian_kde(gls, \"silverman\")\n",
    "\n",
    "# for the OLS estimate switch to this line \n",
    "#kde = gaussian_kde(ols, \"silverman\")\n",
    "\n",
    "alphas = np.linspace(0.2,1.3,512)\n",
    "logDs = np.linspace(-1.5, 1.5, 512)\n",
    "X, Y = np.mgrid[-1.5:1.5:512j, 0.2:1.3:512j]\n",
    "pos = np.vstack([X.ravel(), Y.ravel()])\n",
    "den = np.reshape(kde(pos).T, X.shape) # original density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ce70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting initial estimate\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "ax1.imshow(np.rot90(den), aspect = \"auto\", extent = (-1.5,1.5,0.2,1.3))\n",
    "ax1.set_title(\"Initial pdf estimate\")\n",
    "ax1.set_xlabel(\"log10 D\")\n",
    "ax1.set_ylabel(\"alpha\")\n",
    "\n",
    "denMarg0 = np.sum(den, axis=0)\n",
    "denMarg0 *= 1/(sum(denMarg0)*(1.1/512))\n",
    "\n",
    "ax2.plot(denMarg0, alphas)\n",
    "ax2.set_title(\"Marginal distribution\")\n",
    "ax2.set_ylim(0.2,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64125144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.signal import fftconvolve\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def deconvolve_internal(logDs, alphas, den, C, nIter):\n",
    "    \"\"\"\n",
    "    Performs Richardson-Lucy deconvolution with Gaussian kernel given covariance C.\n",
    "    \"\"\"\n",
    "    res = np.copy(den)\n",
    "    \n",
    "    mean = [logDs[len(logDs) // 2], alphas[len(alphas) // 2]]\n",
    "    mvn = multivariate_normal(mean=mean, cov=C)\n",
    "    \n",
    "    ns = np.array([[mvn.pdf([x, y]) for y in alphas] for x in logDs])\n",
    "    ins = np.flip(ns)\n",
    "\n",
    "    for _ in range(nIter):\n",
    "        d = fftconvolve(res, ns, mode = \"same\")\n",
    "        d[np.abs(d) < 1e-12] = 1e-12\n",
    "        res *= fftconvolve(den / d, ins, mode = \"same\")\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deconvolve_gls(logDs, alphas, den, dt, ln, dim, alpha, method = \"simple\", nIter = 30):\n",
    "    \"\"\"\n",
    "        deconvolve_gls(logDs, alphas, den, dt, ln, dim, alpha, method, nIter = 30)\n",
    "        deconvolve_gls(logDs, alphas, den, dt, ln, dim, (alpha_min,alpha_max), method, nIter = 30)\n",
    "\n",
    "    Deconvolving pdf of estimated (logD, α) obtained with the GLS method. It removes the blur caused by the estimation errors, reconstructing the original distribution of (logD, α). This method assumes the data was FBM.\n",
    "    Input:\n",
    "    - logDs: labels of log diffusivity\n",
    "    - αlphas: labels of anomalous index\n",
    "    - den: density which we want to deconvolve\n",
    "    - dt: sampling inverval\n",
    "    - ln: length of the orignal trajectory used\n",
    "    - dim: trajectory dimension (typically 1, 2 or 3)\n",
    "    - method: \"simple\" or \"full\"\n",
    "    For simple deconvolution provide:\n",
    "    - alpha: the anomalous index value for which deconvolve, should be the most representative of the sample\n",
    "    For full deconvolution provide:\n",
    "    - (alpha_min,alpha_max): range of α for which deconvolve\n",
    "    Full deconvolution is much more computationally expensive, but the result better reflects the original distribution.\n",
    "\n",
    "    Optional input:\n",
    "    - nIter: number of steps in the Richardson-Lucy deconvolution algorithm\n",
    "\n",
    "    Output: matrix with the deconvolved pdf. \n",
    "    \"\"\"\n",
    "    if method == \"simple\":\n",
    "        return deconvolve_gls_simple(logDs, alphas, den, dt, ln, dim, alpha, nIter)\n",
    "    elif method == \"full\":\n",
    "        deconvolve_gls_full(logDs, alphas, den, dt, ln, dim, alpha, nIter)\n",
    "\n",
    "def deconvolve_ols(logDs, alphas, den, dt, ln, dim, alpha, w, method = \"simple\", nIter = 30):\n",
    "    \"\"\"\n",
    "        deconvolve_ols(logDs, alphas, den, dt, ln, dim, alpha, w, method, nIter = 30)\n",
    "        deconvolve_ols(logDs, alphas, den, dt, ln, dim, alpha, w, method, nIter = 30)\n",
    "    Deconvolving pdf of estimated (logD, α) obtained with the OLS method. It removes the blur caused by the estimation errors, reconstructing the original distribution of (logD, α). This method assumes the data was FBM.\n",
    "    Input:\n",
    "    - logDs: labels of log diffusivity\n",
    "    - alphas: labels of anomalous index\n",
    "    - den: density which we want to deconvolve\n",
    "    - dt: sampling inverval\n",
    "    - ln: length of the orignal trajectory used\n",
    "    - dim: trajectory dimension (typically 1, 2 or 3)\n",
    "    - w: size of window in which the OLS was calculated \n",
    "    - method: \"simple\" or \"full\"\n",
    "    For simple deconvolution provide:\n",
    "    - alpha: the value for which deconvolve, should be the most typical in the sample\n",
    "    For full deconvolution provide:\n",
    "    - (alpha_min,alpha_max): range of α for which deconvolve\n",
    "    Full deconvolution is much more computationally expensive, but the result better reflects the original distribution.\n",
    "\n",
    "    Optional input:\n",
    "    - nIter: number of steps in the Richardson-Lucy deconvolution algorithm\n",
    "\n",
    "    Output: matrix with the deconvolved pdf. \n",
    "    \"\"\"\n",
    "    if method == \"simple\":\n",
    "        return deconvolve_gls_simple(logDs, alphas, den, dt, ln, dim, alpha, w, nIter)\n",
    "    elif method == \"full\":\n",
    "        deconvolve_gls_full(logDs, alphas, den, dt, ln, dim, alpha, w, nIter)\n",
    "\n",
    "def deconvolve_gls_simple(logDs, alphas, den, dt, ln, dim, alpha, nIter):\n",
    "    ts = dt * np.arange(1,ln+1) \n",
    "    Ts = np.c_[np.ones(ln-1), np.log10(ts[:-1])]\n",
    "    _, Sigma = an.errCov(ts, dim, alpha)\n",
    "\n",
    "    return deconvolve_internal(logDs, alphas, den, np.linalg.inv(Ts.T @ np.linalg.inv(Sigma) @ Ts), nIter)\n",
    "\n",
    "def deconvolve_ols_simple(logDs, alphas, den, dt, ln, dim, alpha, w, nIter):\n",
    "    ts = dt * np.arange(1,ln+1) \n",
    "    Ts = np.c_[np.ones(w), np.log10(ts[:w])]\n",
    "    _, Sigma = an.errCov(ts, dim, alpha, w)\n",
    "    S = np.linalg.inv(Ts.T @ Ts) @ Ts.T\n",
    "    return deconvolve_internal(logDs, alphas, den, S @ Sigma @ S.T, nIter)\n",
    "\n",
    "def deconvolve_gls_full(logDs, alphas, den, dt, ln, dim, alpha_range, nIter = 30):\n",
    "    alpha_min,alpha_max = alpha_range\n",
    "    ts = dt * np.arange(1,ln+1) \n",
    "    Ts = np.c_[np.ones(ln-1), np.log10(ts[:-1])]\n",
    "    _, Sigma = an.errCov(ts, dim, alpha_min)\n",
    "\n",
    "    res = deconvolve_internal(logDs, alphas, den, np.linalg.inv(Ts.T @ np.linalg.inv(Sigma) @ Ts), nIter)\n",
    "\n",
    "    j1 = np.argmax(alphas >= alpha_min)\n",
    "    j2 = np.argwhere(alphas <= alpha_max).max()\n",
    "\n",
    "    for k in tqdm(range(j1,j2)):\n",
    "        _, Sigma = an.errCov(ts, 1, alphas[k])\n",
    "        zs = deconvolve_internal(logDs, alphas, den, np.linalg.inv(Ts.T @ np.linalg.inv(Sigma) @ Ts), nIter)\n",
    "        res[:,k] = zs[:,k]\n",
    "\n",
    "    _, Sigma = an.errCov(ts, 1, alpha_max )\n",
    "    zs = deconvolve_internal(logDs, alphas, den, np.linalg.inv(Ts.T @ np.linalg.inv(Sigma) @ Ts), nIter)\n",
    "\n",
    "    res[:,j2:] = zs[:,j2:]\n",
    "\n",
    "    res /= (np.sum(res)*(alphas[1]-alphas[0])*(logDs[1]-logDs[0])) # normalise\n",
    "    return res\n",
    "\n",
    "def deconvolve_ols_full(logDs, alphas, den, dt, ln, dim, alpha_range, w, nIter):\n",
    "    alpha_min,alpha_max = alpha_range\n",
    "    ts = dt * np.arange(1,ln+1) \n",
    "    Ts = np.c_[np.ones(w), np.log10(ts[:w])]\n",
    "    _, Sigma = an.errCov(ts, dim, alpha_min, w)\n",
    "    S = np.linalg.inv(Ts.T @ Ts) @ Ts.T\n",
    "\n",
    "    res = deconvolve_internal(logDs, alphas, den, S @ Sigma @ S.T, nIter)\n",
    "\n",
    "    j1 = np.argmax(alphas >= alpha_min)\n",
    "    j2 = np.argwhere(alphas <= alpha_max).max()\n",
    "\n",
    "    for k in tqdm(range(j1,j2)):\n",
    "        _, Sigma = an.errCov(ts, 1, alphas[k], w)\n",
    "        zs = deconvolve_internal(logDs, alphas, den, S @ Sigma @ S.T, nIter)\n",
    "        res[:,k] = zs[:,k]\n",
    "\n",
    "    _, Sigma = an.errCov(ts, 1, alpha_max, w)\n",
    "    zs = deconvolve_internal(logDs, alphas, den, S @ Sigma @ S.T, nIter)\n",
    "\n",
    "    res[:,j2:] = zs[:,j2:]\n",
    "\n",
    "    res /= (np.sum(res)*(alphas[1]-alphas[0])*(logDs[1]-logDs[0])) # normalise\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple deconvolution\n",
    "\n",
    "dim = 1\n",
    "alpha = 0.7 # α for which to deconvolve\n",
    "\n",
    "# calculation\n",
    "deconvolvedPDF1 = deconvolve_gls(logDs, alphas, den, dt, ln, dim, alpha, \"simple\")\n",
    "\n",
    "# for the OLS switch to this lines\n",
    "#w = 10 # OLS window size\n",
    "#deconvolvedPDF1 = deconvolve_ols_simple(logDs, alphas, den, dt, ln, dim, alpha, w, \"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "ax1.imshow(np.rot90(deconvolvedPDF1), aspect = \"auto\", extent = (-1.5,1.5,0.2,1.3))\n",
    "ax1.set_title(\"Deconvolved pdf estimate, simple method\")\n",
    "ax1.set_xlabel(\"log10 D\")\n",
    "ax1.set_ylabel(\"alpha\")\n",
    "\n",
    "denMarg1 = np.sum(deconvolvedPDF1, axis=0)\n",
    "denMarg1 *= 1/(sum(denMarg1)*(1.1/512))\n",
    "\n",
    "ax2.plot(denMarg1, alphas)\n",
    "ax2.set_title(\"Marginal distribution\")\n",
    "ax2.set_ylim(0.2, 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full deconvolution \n",
    "\n",
    "dim = 1\n",
    "alpha_min, alpha_max = 0.3, 1.1 # range of α for which to deconvolve\n",
    "\n",
    "# calculation, note it can take significantly longer time\n",
    "deconvolvedPDF2 = deconvolve_gls(logDs, alphas, den, dt, ln, dim, (alpha_min,alpha_max), \"full\")\n",
    "\n",
    "# for the OLS switch to this lines\n",
    "# w = 10 # OLS window size\n",
    "# deconvolvedPDF2 = deconvolve_ols_full(logDs, alphas, den, dt, ln, dim, (alpha_min,alpha_max), w, \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "ax1.imshow(np.rot90(deconvolvedPDF2), aspect = \"auto\", extent = (-1.5,1.5,0.2,1.3))\n",
    "ax1.set_title(\"Deconvolved pdf estimate, full method\")\n",
    "ax1.set_xlabel(\"log10 D\")\n",
    "ax1.set_ylabel(\"alpha\")\n",
    "\n",
    "denMarg2 = np.sum(deconvolvedPDF2, axis=0)\n",
    "denMarg2 *= 1/(sum(denMarg2)*(1.1/512))\n",
    "\n",
    "ax2.plot(denMarg2, alphas)\n",
    "ax2.set_title(\"Marginal distribution\")\n",
    "ax2.set_ylim(0.2, 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7748891",
   "metadata": {},
   "outputs": [],
   "source": [
    "denMarg2 = np.sum(deconvolvedPDF2, axis=0)\n",
    "denMarg2 *= 1/(sum(denMarg2)*(1.1/512))\n",
    "denMarg1 = np.sum(deconvolvedPDF1, axis=0)\n",
    "denMarg1 *= 1/(sum(denMarg1)*(1.1/512))\n",
    "plt.plot(alphas, denMarg1)\n",
    "plt.plot(alphas,denMarg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b14c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
